---
title: "Practical Machine Learning Course Project"
author: "Jamin Wong"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
library(caret)
library(knitr)
library(ggplot2)
library(lubridate)
library(dplyr)
library(tidyr)
library(rpart)
opts_chunk$set(echo= TRUE, warning = FALSE)
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 60), tidy = TRUE)
```

# Abstract
The goal of the project is to predict the manner in which the subject did the exercise. The variable "classe" is the variable to be predicted.

The approach of the project will be using 

## Weight Lifting Dataset
Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).


## Load data
```{r load_data, cache=TRUE}
trainingset <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", na.strings = c("NA", ""))

testing <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", na.strings = c("NA", ""))
```

# Exploratory Analysis

## Frequency of classes
```{r eda}
g <- ggplot(trainingset, aes(x = classe, fill = classe))
g + geom_bar() + geom_hline(yintercept = dim(trainingset)[1]/5, linetype = "dashed")
```
Class A (exactly according to the specification) has the highest frequency while class D (lowering the dumbbell only halfway) has the lowest frequency.  
Only class A is above the mean count.  

## Read the training set
```{r}
str(trainingset)
```
# Clean data
## Remove column with na
```{r datacleaning1}
trainingset <- trainingset %>% select_if(~ !any(is.na(.)))
testing <- testing %>% select_if(~ !any(is.na(.)))
```
## Remove timesstamp and index
```{r datacleaning2}
toBeRemove <- grep("timestamp|^X|user_name|new_window", names(trainingset))
trainingset <- trainingset[,-toBeRemove]
testing <- testing[,-toBeRemove]
trainingset <- mutate_if(trainingset, is.character, as.factor)
testing <- mutate_if(testing, is.character, as.factor)
```
## Create cross validation set
```{r create_cross_validation}
set.seed(1234)
inTrain <- createDataPartition(trainingset$classe, p = 0.8, list = FALSE)
training <- trainingset[inTrain,]
cvd <- trainingset[-inTrain,]
```


# Model Training

## Decision Tree
```{r dt_train, cache=TRUE}
dtmod <- rpart(classe ~ ., data=training, method="class")

resultdt <- predict(dtmod, newdata = cvd, type = "class")

dtmat <- confusionMatrix(resultdt, cvd$classe)
```

### Confusion Matrix (Decision Tree)
```{r dt_mat}
dtmat
```

## Random Forest
```{r randomforest_train, cache = TRUE}
rfmod <- train(classe~., method = "rf",data = training, trControl = trainControl(method = "cv", number = 3), metric="Accuracy")

resultrf <- predict(rfmod, newdata = cvd)

rfmat <- confusionMatrix(resultrf, cvd$classe)

```

### Confusion Matrix (Random Forest)
```{r rfmat}
rfmat
```

# Result
The Random Forest model has a higher accuracy of `r rfmat$overall[["Accuracy"]]`  than that of decision tree of `r dtmat$overall[["Accuracy"]]`.  
Hence, the random forest model will be used.

## Out of sample error
The out of sample error will be `r 1-rfmat$overall[["Accuracy"]]`.

## Prediction of the testing set
```{r predict}
result <- predict(rfmod, newdata = testing)

result
```
